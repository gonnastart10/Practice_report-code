{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего паков:  214\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import csv\n",
    "#social_netork='fb'\n",
    "pcks=[]\n",
    "with open('trans.csv', 'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "    pcks=[]\n",
    "    spamreader.next()\n",
    "    for row in spamreader:\n",
    "        if (row[5] not in pcks):\n",
    "            pcks.append(row[5])\n",
    "    print \"Всего паков: \",len(pcks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For checking:\n",
    "\n",
    "a,b,c\n",
    "\n",
    "c,b,d\n",
    "\n",
    "a,b\n",
    "\n",
    "b,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#id_pack_period={1:[[\"a\",2,6,5,657],[\"b\",3,343],[\"c\",5,8,9,100],[\"d\",1000]], 2:[[\"c\",2,110],[\"b\",230,3],[\"d\",123,4]],3:[[\"a\",1],[\"b\",2]],4:[[\"b\",34,3],[\"a\",9]],4:[[\"c\",123]]}\n",
    "#1-10  #For checking\n",
    "\n",
    "#st_t=0\n",
    "#end_t=10\n",
    "\n",
    "#id_p={}\n",
    "\n",
    "#for key, v in id_pack_period.items():\n",
    "#        for t in v:\n",
    "#            print t\n",
    "#            tmpp=[]\n",
    "#            for itr in range(0,len(t)-1):\n",
    "#                if t[itr+1]>=st_t and t[itr+1]<=end_t:\n",
    "#                    tmpp.append(t[itr+1])\n",
    "#                    print t[itr+1]\n",
    "#            if len(tmpp)!=0:\n",
    "#                if id_p.has_key(key)==False:\n",
    "#                    id_p[key]=[]\n",
    "#                tmpp_1=[]\n",
    "#                tmpp_1.append(t[0]) ### ключ : [[pack,[times]]    ]\n",
    "#                tmpp_1.append(sorted(tmpp))   ### сортирует по возрастанию\n",
    "#                print \"\\n\",tmpp_1\n",
    "#                id_p[key].append(tmpp_1)\n",
    "#id_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "\n",
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "\n",
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "        \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "       of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "        _itemSet = set()\n",
    "        localSet = defaultdict(int)\n",
    "\n",
    "        for item in itemSet:\n",
    "                for transaction in transactionList:\n",
    "                        if item.issubset(transaction):\n",
    "                                freqSet[item] += 1\n",
    "                                localSet[item] += 1\n",
    "\n",
    "        for item, count in localSet.items():\n",
    "                support = float(count)/len(transactionList)\n",
    "\n",
    "                if support >= minSupport:\n",
    "                        _itemSet.add(item)\n",
    "\n",
    "        return _itemSet\n",
    "\n",
    "\n",
    "def joinSet(itemSet, length):\n",
    "        \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "        return set([i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length])\n",
    "\n",
    "\n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))              # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "\n",
    "\n",
    "def runApriori(data_iter, minSupport, minConfidence, st_t, end_t):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet,\n",
    "                                        transactionList,\n",
    "                                        minSupport,\n",
    "                                        freqSet)\n",
    "\n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while(currentLSet != set([])):\n",
    "        largeSet[k-1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(currentLSet,\n",
    "                                                transactionList,\n",
    "                                                minSupport,\n",
    "                                                freqSet)\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "            \"\"\"local function which Returns the support of an item\"\"\"\n",
    "            return float(freqSet[item])/len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in largeSet.items():\n",
    "        toRetItems.extend([(tuple(item), getSupport(item))\n",
    "                           for item in value])\n",
    "    #print len(id_pack_period)\n",
    "    toRetRules = []\n",
    "    id_p={}\n",
    "    for key, v in id_pack_period.items():\n",
    "        for t in v:\n",
    "            tmpp=[]\n",
    "            for itr in range(0,len(t)-1):\n",
    "                if t[itr+1]>=st_t and t[itr+1]<=end_t:\n",
    "                    tmpp.append(t[itr+1])\n",
    "            if len(tmpp)!=0:\n",
    "                if id_p.has_key(key)==False:\n",
    "                    id_p[key]=[]\n",
    "                tmpp_1=[]\n",
    "                tmpp_1.append(t[0]) ### ключ : [[pack,[times]]    ]\n",
    "                tmpp_1.append(sorted(tmpp))   ### сортирует по возрастанию\n",
    "                id_p[key].append(tmpp_1)\n",
    "    #print id_p\n",
    "                \n",
    "    for key, value in largeSet.items()[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence_lift = []\n",
    "                    item_A=getSupport(element)\n",
    "                    \n",
    "                    item_B=getSupport(remain)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    confidence_lift.append(getSupport(item)/item_A)#conf - 0\n",
    "                    if confidence_lift[0] >= minConfidence:\n",
    "                        \n",
    "                        count=0\n",
    "                    \n",
    "                        l_s=str(tuple(element))\n",
    "                        l=l_s.strip(\"(\").strip(\")\").strip(\",\").split(\",\")\n",
    "                        for i in range(0,len(l)):\n",
    "                            l[i]=l[i].strip(\"'\")\n",
    "                        \n",
    "                        r_s=str(tuple(remain))\n",
    "                        r=r_s.strip(\"(\").strip(\")\").strip(\",\").split(\",\")\n",
    "                        for i in range(0,len(r)):\n",
    "                            r[i]=r[i].strip(\"'\")\n",
    "\n",
    "                        for k,v in id_p.items():# проверяем последовательность\n",
    "                            accs=True\n",
    "                            tmp=[]\n",
    "                            for it in v:\n",
    "                                tmp.append(it[0])# все паки у пользователя (в данном промежутке времени)\n",
    "                            for j in l:\n",
    "                                if j not in tmp:\n",
    "                                    accs=False\n",
    "                            for j in r:\n",
    "                                if j not in tmp:\n",
    "                                    accs=False\n",
    "                            \n",
    "                            if accs==True: #если у него все паки есть\n",
    "                                min_left=None\n",
    "                                max_right=None\n",
    "                                for it in v:\n",
    "                                    if it[0] in l:\n",
    "                                        if min_left==None:\n",
    "                                            min_left=it[1][0]\n",
    "                                        else:\n",
    "                                            if it[1][1]<min_left:\n",
    "                                                min_left=it[1][0]\n",
    "                                    if it[0] in r:\n",
    "                                        if max_right==None:\n",
    "                                            max_right=it[1][len(it[1])-1]\n",
    "                                        else:\n",
    "                                            if t[1][len(it[1])-1]>max_right:\n",
    "                                                max_right=it[1][len(it[1])-1]\n",
    "                                if max_right>=min_left:\n",
    "                                    count += 1\n",
    "                        confidence_lift[0]=(float(count)/(float(len(transactionList))*float(item_A)))#conf - 0\n",
    "                        #print confidence_lift[0],\",\",\n",
    "                        if confidence_lift[0] >= minConfidence:    \n",
    "                            \n",
    "                            confidence_lift.append(getSupport(item)/(item_A*item_B))#lift - 1\n",
    "                            if  item_A>item_B:\n",
    "                                confidence_lift.append(item_B)#min(minsup) - 2\n",
    "                            else:\n",
    "                                confidence_lift.append(item_A)\n",
    "                            #print \"=================\"        #For checking\n",
    "                            #print element,\"---\",item_A       #For checking\n",
    "                            #print remain,\"---\",item_B      \n",
    "\n",
    "                            #print item,\"---\",float(count)/float(len(transactionList)),\"===\",len(transactionList) #For checking\n",
    "                            #print \"\\n\"                       #For checking\n",
    "                            #print str(tuple(element)),\"===>\",tuple(remain),\"conf\",confidence_lift[0]  #For checking\n",
    "                            #print \"=================\\n\\n\"    #For checking\n",
    "                            toRetRules.append(((tuple(element), tuple(remain)),\n",
    "                                               confidence_lift))\n",
    "    #print id_p\n",
    "    return toRetItems, toRetRules\n",
    "\n",
    "\n",
    "\n",
    "def dataFromFile(fname):\n",
    "        \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "        file_iter = open(fname, 'rU')\n",
    "        for line in file_iter:\n",
    "                line = line.strip().rstrip(',')                         # Remove trailing comma\n",
    "                record = frozenset(line.split(','))\n",
    "                yield record\n",
    "                \n",
    "def printResults(items, rules, rs,it, idc, t_d,start_date,end_date, len_ids): \n",
    "                                        #принимает: итемы для минсапа, правила с конф, файл для записи результата,\n",
    "                                        #название текущего пака, номер айдишника для записи в словарь данных по пакам (tableau),\n",
    "                                        #словарь, дата начала и конца, кол-во транзакций в периоде\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    if len(rules)!=0:\n",
    "        rs.write(\"SUP------------SUP------------SUP:\\n\")\n",
    "        rs.write(\"For time boundaries on: \"+it+\"\\n\") #показывает периоды какого пака исследуются\n",
    "        for item, support in sorted(items, key=lambda (item, support): support):\n",
    "            rs.write(\"item: %s , %.3f \\n\" % (str(item), support))\n",
    "            #print \"item: %s , %.3f\" % (str(item), support)\n",
    "        rs.write(\"\\nRULES------------RULES------------RULES:\\n\")\n",
    "        for rule, confidence in sorted(rules, key=lambda (rule, confidence): confidence):\n",
    "            pre, post = rule\n",
    "            idc=idc+1\n",
    "            t_d[idc]=[]\n",
    "            st_st=\"%s ==> %s\"%(str(pre), str(post))\n",
    "            t_d[idc].append(st_st)#rule \n",
    "            t_d[idc].append(confidence[0])#conf\n",
    "            t_d[idc].append(confidence[1])#lift\n",
    "            t_d[idc].append(confidence[2])#min minsup\n",
    "            if \"fb_\" in str(pre)[:7]:\n",
    "                if \"fb_\" in str(post)[:7]:\n",
    "                    t_d[idc].append(\"fb\") #social_network\n",
    "                else:\n",
    "                    t_d[idc].append(\"cross\")\n",
    "            elif \"vk_\" in str(pre)[:7]:\n",
    "                if \"vk_\" in str(post)[:7]:\n",
    "                    t_d[idc].append(\"vk\") #social_network\n",
    "                else:\n",
    "                    t_d[idc].append(\"cross\")\n",
    "            elif \"ok_\" in str(pre)[:7]:\n",
    "                if \"ok_\" in str(post)[:7]:\n",
    "                    t_d[idc].append(\"ok\") #social_network\n",
    "                else:\n",
    "                    t_d[idc].append(\"cross\")\n",
    "            elif \"mm_\" in str(pre)[:7]:\n",
    "                if \"mm_\" in str(post)[:7]:\n",
    "                    t_d[idc].append(\"mm\") #social_network\n",
    "                else:\n",
    "                    t_d[idc].append(\"cross\")\n",
    "            else:\n",
    "                t_d[idc].append(\" \")\n",
    "            date_for_period=str(date.fromtimestamp(start_date))+\" to \"+str(date.fromtimestamp(end_date))\n",
    "            t_d[idc].append(date_for_period)#date\n",
    "            t_d[idc].append(len_ids)# number of transactions in period\n",
    "            \n",
    "            l_s=str(pre)\n",
    "            r_s=str(post)\n",
    "            access_act = False\n",
    "            l=l_s.strip(\"(\").strip(\")\").strip(\",\").split(\",\")\n",
    "            for i in range(0,len(l)):\n",
    "                l[i]=l[i].strip(\"'\")\n",
    "                if l[i] in action_pack:\n",
    "                    access_act=True\n",
    "            r=r_s.strip(\"(\").strip(\")\").strip(\",\").split(\",\")\n",
    "            for i in range(0,len(r)):\n",
    "                r[i]=r[i].strip(\"'\")\n",
    "                if r[i] in action_pack:\n",
    "                    access_act=True\n",
    "            if access_act==True:\n",
    "                t_d[idc].append(\"y\")# if rule consist action pack\n",
    "            else:\n",
    "                t_d[idc].append(\"n\")\n",
    "            rs.write(\"Rule: %s ==> %s , confidence: %.3f, lift: %.3f, min(minsup) %.3f\\n\" % (str(pre), str(post), confidence[0], confidence[1], confidence[2]))\n",
    "        rs.write(\"\\n-----------------------------------------\\n\")\n",
    "        rs.write(\"\\n\")\n",
    "    return idc, t_d\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    optparser = OptionParser()\n",
    "    optparser.add_option('-f', '--inputFile',\n",
    "                         dest='input',\n",
    "                         help='filename containing csv',\n",
    "                         default=None)\n",
    "    optparser.add_option('-s', '--minSupport',\n",
    "                         dest='minS',\n",
    "                         help='minimum support value',\n",
    "                         default=0.15,\n",
    "                         type='float')\n",
    "    optparser.add_option('-c', '--minConfidence',\n",
    "                         dest='minC',\n",
    "                         help='minimum confidence value',\n",
    "                         default=0.6,\n",
    "                         type='float')\n",
    "\n",
    "    (options, args) = optparser.parse_args()\n",
    "\n",
    "\n",
    "    inFile = dataFromFile(\"fool.csv\")\n",
    "\n",
    "    minSupport = options.minS\n",
    "    minConfidence = options.minC\n",
    "\n",
    "    #items, rules = runApriori(inFile, minSupport, 0.2,0 , 10) #For checking\n",
    "\n",
    "    #printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_action_packs_with_periods(which): #which определяет какие именно паки - \"all\", \"fb\", \"vk\", \"mm\", \"ok\"\n",
    "    action_pack={}\n",
    "    allowed_packs=[\"fb\",\"vk\",\"mm\",\"ok\"]\n",
    "    for it in pcks:\n",
    "        if ( (which in allowed_packs) and (which in it[:2]) ) or which not in allowed_packs:\n",
    "            times=[]\n",
    "            # 1) составляем временные промежутки для паков\n",
    "\n",
    "            with open('trans.csv', 'rb') as csvfile:\n",
    "                spamreader = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "                spamreader.next()\n",
    "                for row in spamreader:\n",
    "                    if row[5]==it:\n",
    "                        times.append(int(row[2]))\n",
    "\n",
    "            difference=172800+43200 # = 2.5 days in seconds\n",
    "            # сравниваем даты по timestamp\n",
    "            # если покупки наблюдались в окрестности 2х дней, то\n",
    "            # будем считать, что в эти дни акция действовала\n",
    "            times.sort()\n",
    "\n",
    "            start_time=[]\n",
    "            end_time=[]\n",
    "\n",
    "            beg=times[0]\n",
    "\n",
    "            start_time.append(beg)\n",
    "            for item in times:\n",
    "                if beg+difference>=item:\n",
    "                    beg=item\n",
    "                else:\n",
    "                    start_time.append(item)\n",
    "                    end_time.append(beg)\n",
    "                    beg=item\n",
    "            end_time.append(beg)\n",
    "\n",
    "            # 2) проверяем временные промежутки; если все промежутки лежат в рамках 2.5 недель,\n",
    "            # то считаем пак акционным и проходимся априори алгоритмом по выявленным промежуткам\n",
    "\n",
    "            week_time=604800 # week time\n",
    "            access=True\n",
    "            for i in range(0,len(start_time)):\n",
    "                if end_time[i]-start_time[i] > week_time*2.5: # предполагаем, что акции длятся не более 2х с половиной недель\n",
    "                    access=False\n",
    "            if access==True:\n",
    "                action_pack[it]=[]\n",
    "                action_pack[it].append(start_time)\n",
    "                action_pack[it].append(end_time)\n",
    "    return action_pack\n",
    "                \n",
    "#action_pack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:23.848244\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "action_pack=find_action_packs_with_periods(\"all\") # любая строка, кроме fb, vk, mm, ok будет искать все паки\n",
    "now1 = datetime.now()\n",
    "print (now1-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_pack_period={}\n",
    "with open('trans.csv', 'rb') as csvfile:\n",
    "    spam = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "    spam.next()\n",
    "    for row in spam:\n",
    "        if id_pack_period.has_key(int(row[0]))==True:\n",
    "            val=id_pack_period.get(int(row[0]))\n",
    "            acs=False\n",
    "            for it in val:\n",
    "                if it[0]==row[5]:\n",
    "                    acs=True\n",
    "                    it.append(int(row[2]))\n",
    "            if acs==False:\n",
    "                temp=[]\n",
    "                temp.append(row[5])#название соц. сети\n",
    "                temp.append(int(row[2]))#время\n",
    "                id_pack_period[int(row[0])].append(temp)\n",
    "        else:\n",
    "            id_pack_period[int(row[0])]=[]# каждый id принимает в значение свои транзакции\n",
    "            temp=[]\n",
    "            temp.append(row[5])#название соц. сети\n",
    "            temp.append(int(row[2]))#время\n",
    "            id_pack_period[int(row[0])].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    from datetime import datetime\n",
    "    from datetime import date\n",
    "    def write_res_to_file_name(file_name, mnsp, mncf, t_d):\n",
    "        id_count=0\n",
    "        now = datetime.now()\n",
    "        minSupport=mnsp\n",
    "        minConfidence=mncf\n",
    "    \n",
    "        count=0\n",
    "        with open(file_name, 'w') as rs:\n",
    "            for it,time_st_end in action_pack.items():\n",
    "                start_time=time_st_end[0]\n",
    "                end_time=time_st_end[1]\n",
    "                for bound in range(0,len(start_time)):\n",
    "                    ids={}\n",
    "                    # 3) если пак акционный, то забиваем данные для составления ассоциативных правил\n",
    "                    \n",
    "                    for id_id in id_pack_period:\n",
    "                        temp=[]\n",
    "                        for packs in id_pack_period[id_id]:\n",
    "                            acs=False\n",
    "                            for iterator in range(0,len(packs)-1): # проверяем покупался ли пак данным пользователем в данный промежуток времени\n",
    "                                if (packs[iterator+1]>=start_time[bound] and packs[iterator+1]<=end_time[bound]):\n",
    "                                    acs=True\n",
    "                            if acs==True:\n",
    "                                temp.append(packs[0])\n",
    "                        if len(temp)!=0:\n",
    "                            ids[id_id]=[]\n",
    "                            for item in  temp:\n",
    "                                ids[id_id].append(item)\n",
    "                    \n",
    "                    with open('file_for_transactions.csv', 'w') as csf:\n",
    "                        for key, value in ids.items():\n",
    "                            st=\"\"\n",
    "                            for i in range(0,len(value)):\n",
    "                                st=st+value[i]+','\n",
    "                            csf.write(st+'\\n')\n",
    "                    #now1 = datetime.now()\n",
    "                    #print \"файлы: \",\"  \",(now1-now)\n",
    "\n",
    "                    inFile = dataFromFile(\"file_for_transactions.csv\")\n",
    "                    items, rules = runApriori(inFile, minSupport, minConfidence, start_time[bound], end_time[bound])    \n",
    "                    id_count, t_d=printResults(items, rules, rs,it, id_count, t_d, start_time[bound],end_time[bound],len(ids))\n",
    "                    #print len(ids),\"-\",\n",
    "                    \n",
    "\n",
    "\n",
    "        # 4) время работы алгоритма\n",
    "        now1 = datetime.now()\n",
    "        print (now1-now)\n",
    "        return t_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:50.894327\n"
     ]
    }
   ],
   "source": [
    "tabl_dict={}\n",
    "tabl_dict=write_res_to_file_name(\"res_l1_check_seq_1.txt\", 0.05, 0.5,tabl_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Результат](https://public.tableau.com/profile/publish/Rule-Infconsideringsequence/Dashboard1#!/publish-confirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('good_thing_to_do_seq.csv', 'w') as csvfile_1:\n",
    "    fieldnames=[\"ID\",\"Rule\",\"Confidence\",\"Lift\",\"Support\",\"Social_network\",\"Date\",\"Number_of_transactions_in_period\",\"Consist_action_pack\"]\n",
    "    writer = csv.DictWriter(csvfile_1, fieldnames=fieldnames,delimiter='|')\n",
    "    writer.writeheader()\n",
    "    for key,value in tabl_dict.items():\n",
    "        #print value[4],\n",
    "        writer.writerow({fieldnames[0]: key, fieldnames[1]: value[0], fieldnames[2]: value[1], fieldnames[3]: value[2],fieldnames[4]: value[3],fieldnames[5]: value[4],fieldnames[6]: value[5],fieldnames[7]: value[6],fieldnames[8]: value[7]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
