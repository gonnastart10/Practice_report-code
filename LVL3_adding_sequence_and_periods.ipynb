{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего паков:  214\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import csv\n",
    "#social_netork='fb'\n",
    "pcks=[]\n",
    "with open('trans.csv', 'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "    pcks=[]\n",
    "    spamreader.next()\n",
    "    for row in spamreader:\n",
    "        if (row[5] not in pcks):\n",
    "            pcks.append(row[5])\n",
    "    print \"Всего паков: \",len(pcks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДОБАВЛЕНО: \n",
    "\n",
    "- если проходит порог **minconfidence** с учетом порядка, то, ко всем айдишникам, где встречалось данное правило добавляется данное правило с новой инициализацией\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "\n",
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "\n",
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "        \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "       of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "        _itemSet = set()\n",
    "        localSet = defaultdict(int)\n",
    "\n",
    "        for item in itemSet:\n",
    "                for transaction in transactionList:\n",
    "                        if item.issubset(transaction):\n",
    "                                freqSet[item] += 1\n",
    "                                localSet[item] += 1\n",
    "\n",
    "        for item, count in localSet.items():\n",
    "                support = float(count)/len(transactionList)\n",
    "\n",
    "                if support >= minSupport:\n",
    "                        _itemSet.add(item)\n",
    "\n",
    "        return _itemSet\n",
    "\n",
    "\n",
    "def joinSet(itemSet, length):\n",
    "        \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "        return set([i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length])\n",
    "\n",
    "\n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))              # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "\n",
    "\n",
    "def runApriori(data_iter, minSupport, minConfidence, st_t, end_t, r_f_a, r_d):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet,\n",
    "                                        transactionList,\n",
    "                                        minSupport,\n",
    "                                        freqSet)\n",
    "\n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while(currentLSet != set([])):\n",
    "        largeSet[k-1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(currentLSet,\n",
    "                                                transactionList,\n",
    "                                                minSupport,\n",
    "                                                freqSet)\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "            \"\"\"local function which Returns the support of an item\"\"\"\n",
    "            return float(freqSet[item])/len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in largeSet.items():\n",
    "        toRetItems.extend([(tuple(item), getSupport(item))\n",
    "                           for item in value])\n",
    "    #print len(id_pack_period)\n",
    "    toRetRules = []\n",
    "    id_p={}\n",
    "    for key, v in id_pack_period.items():\n",
    "        for t in v:\n",
    "            tmpp=[]\n",
    "            for itr in range(0,len(t)-1):\n",
    "                if t[itr+1]>=st_t and t[itr+1]<=end_t:\n",
    "                    tmpp.append(t[itr+1])\n",
    "            if len(tmpp)!=0:\n",
    "                if id_p.has_key(key)==False:\n",
    "                    id_p[key]=[]\n",
    "                tmpp_1=[]\n",
    "                tmpp_1.append(t[0]) ### ключ : [[pack,[times]]    ]\n",
    "                tmpp_1.append(sorted(tmpp))   ### сортирует по возрастанию\n",
    "                id_p[key].append(tmpp_1)\n",
    "    #print id_p\n",
    "    \n",
    "    temp_dict=[]\n",
    "    \n",
    "    \n",
    "    for key, value in largeSet.items()[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence_lift = []\n",
    "                    item_A=getSupport(element)\n",
    "                    \n",
    "                    item_B=getSupport(remain)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    confidence_lift.append(getSupport(item)/item_A)#conf - 0\n",
    "                    if confidence_lift[0] >= minConfidence:\n",
    "                        \n",
    "                        count=0\n",
    "                    \n",
    "                        l_s=str(tuple(element))\n",
    "                        l=l_s.strip(\"(\").strip(\")\").strip(\",\").split(\",\")\n",
    "                        for i in range(0,len(l)):\n",
    "                            l[i]=l[i].strip(\"'\")\n",
    "                        \n",
    "                        r_s=str(tuple(remain))\n",
    "                        r=r_s.strip(\"(\").strip(\")\").strip(\",\").split(\",\")\n",
    "                        for i in range(0,len(r)):\n",
    "                            r[i]=r[i].strip(\"'\")\n",
    "\n",
    "                        for k,v in id_p.items():# проверяем последовательность\n",
    "                            accs=True\n",
    "                            tmp=[]\n",
    "                            for it in v:\n",
    "                                tmp.append(it[0])# все паки у пользователя (в данном промежутке времени)\n",
    "                            for j in l:\n",
    "                                if j not in tmp:\n",
    "                                    accs=False\n",
    "                            for j in r:\n",
    "                                if j not in tmp:\n",
    "                                    accs=False\n",
    "                            \n",
    "                            if accs==True: #если у него все паки есть\n",
    "                                min_left=None\n",
    "                                max_right=None\n",
    "                                for it in v:\n",
    "                                    if it[0] in l:\n",
    "                                        if min_left==None:\n",
    "                                            min_left=it[1][0]\n",
    "                                        else:\n",
    "                                            if it[1][1]<min_left:\n",
    "                                                min_left=it[1][0]\n",
    "                                    if it[0] in r:\n",
    "                                        if max_right==None:\n",
    "                                            max_right=it[1][len(it[1])-1]\n",
    "                                        else:\n",
    "                                            if t[1][len(it[1])-1]>max_right:\n",
    "                                                max_right=it[1][len(it[1])-1]\n",
    "                                if max_right>=min_left:\n",
    "                                    #temp_dict[k]=[]# создаем временный словарь айдишник - пак, если проходит по конфиденс то добавляем в текущий\n",
    "                                    temp_dict.append(k)\n",
    "                                        \n",
    "                                    count += 1\n",
    "                        confidence_lift[0]=(float(count)/(float(len(transactionList))*float(item_A)))#conf - 0\n",
    "                        #print confidence_lift[0],\",\",\n",
    "                        if confidence_lift[0] >= minConfidence:\n",
    "                            #print temp_dict\n",
    "                            inddd=str(len(r_d))\n",
    "                            \n",
    "                            date_for_period=str(date.fromtimestamp(st_t))+\" to \"+str(date.fromtimestamp(end_t))\n",
    "                            \n",
    "                            r_d[inddd]=[]\n",
    "                            r_d[inddd].append(l_s+\"==>\"+r_s) #идентифицируем правила\n",
    "                            r_d[inddd].append(date_for_period)#date\n",
    "                            \n",
    "                            for kkey in temp_dict: #добавляем появившиеся транзакции\n",
    "                                if r_f_a.has_key(kkey)==True:\n",
    "                                    r_f_a[kkey].append(inddd)\n",
    "                                else:\n",
    "                                    r_f_a[kkey]=[]\n",
    "                                    r_f_a[kkey].append(inddd)\n",
    "                            temp_dict=[]\n",
    "                            \n",
    "                            confidence_lift.append(getSupport(item)/(item_A*item_B))#lift - 1\n",
    "                            if  item_A>item_B:\n",
    "                                confidence_lift.append(item_B)#min(minsup) - 2\n",
    "                            else:\n",
    "                                confidence_lift.append(item_A)\n",
    "                            #print \"=================\"        #For checking\n",
    "                            #print element,\"---\",item_A       #For checking\n",
    "                            #print remain,\"---\",item_B      \n",
    "\n",
    "                            #print item,\"---\",float(count)/float(len(transactionList)),\"===\",len(transactionList) #For checking\n",
    "                            #print \"\\n\"                       #For checking\n",
    "                            #print str(tuple(element)),\"===>\",tuple(remain),\"conf\",confidence_lift[0]  #For checking\n",
    "                            #print \"=================\\n\\n\"    #For checking\n",
    "                            toRetRules.append(((tuple(element), tuple(remain)),\n",
    "                                               confidence_lift))\n",
    "                        else:\n",
    "                            temp_dict=[]\n",
    "    #print id_p\n",
    "    return toRetItems, toRetRules, r_f_a, r_d\n",
    "\n",
    "\n",
    "\n",
    "def dataFromFile(fname):\n",
    "        \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "        file_iter = open(fname, 'rU')\n",
    "        for line in file_iter:\n",
    "                line = line.strip().rstrip(',')                         # Remove trailing comma\n",
    "                record = frozenset(line.split(','))\n",
    "                yield record\n",
    "                \n",
    "def printResults(items, rules, rs, idc, t_d,start_date,end_date, len_ids): \n",
    "                                        #принимает: итемы для минсапа, правила с конф, файл для записи результата,\n",
    "                                        #название текущего пака, номер айдишника для записи в словарь данных по пакам (tableau),\n",
    "                                        #словарь, дата начала и конца, кол-во транзакций в периоде\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    if len(rules)!=0:\n",
    "        rs.write(\"SUP------------SUP------------SUP:\\n\")\n",
    "        rs.write(\"For time boundaries on: \"+\"\\n\") #показывает периоды какого пака исследуются\n",
    "        for item, support in sorted(items, key=lambda (item, support): support):\n",
    "            rs.write(\"item: %s , %.3f \\n\" % (str(item), support))\n",
    "            #print \"item: %s , %.3f\" % (str(item), support)\n",
    "        rs.write(\"\\nRULES------------RULES------------RULES:\\n\")\n",
    "        for rule, confidence in sorted(rules, key=lambda (rule, confidence): confidence):\n",
    "            pre, post = rule\n",
    "            idc=idc+1\n",
    "            t_d[idc]=[]\n",
    "            st_st=\"%s ==> %s\"%(str(pre), str(post))\n",
    "            t_d[idc].append(st_st)#rule \n",
    "            t_d[idc].append(confidence[0])#conf\n",
    "            t_d[idc].append(confidence[1])#lift\n",
    "            t_d[idc].append(confidence[2])#min minsup\n",
    "            if \"fb_\" in str(pre)[:7]:\n",
    "                if \"fb_\" in str(post)[:7]:\n",
    "                    t_d[idc].append(\"fb\") #social_network\n",
    "                else:\n",
    "                    t_d[idc].append(\"cross\")\n",
    "            elif \"vk_\" in str(pre)[:7]:\n",
    "                if \"vk_\" in str(post)[:7]:\n",
    "                    t_d[idc].append(\"vk\") #social_network\n",
    "                else:\n",
    "                    t_d[idc].append(\"cross\")\n",
    "            elif \"ok_\" in str(pre)[:7]:\n",
    "                if \"ok_\" in str(post)[:7]:\n",
    "                    t_d[idc].append(\"ok\") #social_network\n",
    "                else:\n",
    "                    t_d[idc].append(\"cross\")\n",
    "            elif \"mm_\" in str(pre)[:7]:\n",
    "                if \"mm_\" in str(post)[:7]:\n",
    "                    t_d[idc].append(\"mm\") #social_network\n",
    "                else:\n",
    "                    t_d[idc].append(\"cross\")\n",
    "            else:\n",
    "                t_d[idc].append(\" \")\n",
    "            date_for_period=str(date.fromtimestamp(start_date))+\" to \"+str(date.fromtimestamp(end_date))\n",
    "            t_d[idc].append(date_for_period)#date\n",
    "            t_d[idc].append(len_ids)# number of transactions in period\n",
    "            \n",
    "            l_s=str(pre)\n",
    "            r_s=str(post)\n",
    "            access_act = False\n",
    "            l=l_s.strip(\"(\").strip(\")\").strip(\",\").split(\",\")\n",
    "            for i in range(0,len(l)):\n",
    "                l[i]=l[i].strip(\"'\")\n",
    "                if l[i] in action_pack:\n",
    "                    access_act=True\n",
    "            r=r_s.strip(\"(\").strip(\")\").strip(\",\").split(\",\")\n",
    "            for i in range(0,len(r)):\n",
    "                r[i]=r[i].strip(\"'\")\n",
    "                if r[i] in action_pack:\n",
    "                    access_act=True\n",
    "            if access_act==True:\n",
    "                t_d[idc].append(\"y\")# if rule consist action pack\n",
    "            else:\n",
    "                t_d[idc].append(\"n\")\n",
    "            rs.write(\"Rule: %s ==> %s , confidence: %.3f, lift: %.3f, min(minsup) %.3f\\n\" % (str(pre), str(post), confidence[0], confidence[1], confidence[2]))\n",
    "        rs.write(\"\\n-----------------------------------------\\n\")\n",
    "        rs.write(\"\\n\")\n",
    "    return idc, t_d\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    optparser = OptionParser()\n",
    "    optparser.add_option('-f', '--inputFile',\n",
    "                         dest='input',\n",
    "                         help='filename containing csv',\n",
    "                         default=None)\n",
    "    optparser.add_option('-s', '--minSupport',\n",
    "                         dest='minS',\n",
    "                         help='minimum support value',\n",
    "                         default=0.15,\n",
    "                         type='float')\n",
    "    optparser.add_option('-c', '--minConfidence',\n",
    "                         dest='minC',\n",
    "                         help='minimum confidence value',\n",
    "                         default=0.6,\n",
    "                         type='float')\n",
    "\n",
    "    (options, args) = optparser.parse_args()\n",
    "\n",
    "\n",
    "    inFile = dataFromFile(\"fool.csv\")\n",
    "\n",
    "    minSupport = options.minS\n",
    "    minConfidence = options.minC\n",
    "\n",
    "    #items, rules = runApriori(inFile, minSupport, 0.2,0 , 10) #For checking\n",
    "\n",
    "    #printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_action_packs_with_periods(which): #which определяет какие именно паки - \"all\", \"fb\", \"vk\", \"mm\", \"ok\"\n",
    "    action_pack={}\n",
    "    allowed_packs=[\"fb\",\"vk\",\"mm\",\"ok\"]\n",
    "    for it in pcks:\n",
    "        if ( (which in allowed_packs) and (which in it[:2]) ) or which not in allowed_packs:\n",
    "            times=[]\n",
    "            # 1) составляем временные промежутки для паков\n",
    "\n",
    "            with open('trans.csv', 'rb') as csvfile:\n",
    "                spamreader = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "                spamreader.next()\n",
    "                for row in spamreader:\n",
    "                    if row[5]==it:\n",
    "                        times.append(int(row[2]))\n",
    "\n",
    "            difference=172800+43200 # = 2.5 days in seconds\n",
    "            # сравниваем даты по timestamp\n",
    "            # если покупки наблюдались в окрестности 2х дней, то\n",
    "            # будем считать, что в эти дни акция действовала\n",
    "            times.sort()\n",
    "\n",
    "            start_time=[]\n",
    "            end_time=[]\n",
    "\n",
    "            beg=times[0]\n",
    "\n",
    "            start_time.append(beg)\n",
    "            for item in times:\n",
    "                if beg+difference>=item:\n",
    "                    beg=item\n",
    "                else:\n",
    "                    start_time.append(item)\n",
    "                    end_time.append(beg)\n",
    "                    beg=item\n",
    "            end_time.append(beg)\n",
    "\n",
    "            # 2) проверяем временные промежутки; если все промежутки лежат в рамках 2.5 недель,\n",
    "            # то считаем пак акционным и проходимся априори алгоритмом по выявленным промежуткам\n",
    "\n",
    "            week_time=604800 # week time\n",
    "            access=True\n",
    "            for i in range(0,len(start_time)):\n",
    "                if end_time[i]-start_time[i] > week_time*2.5: # предполагаем, что акции длятся не более 2х с половиной недель\n",
    "                    access=False\n",
    "            if access==True:\n",
    "                action_pack[it]=[]\n",
    "                action_pack[it].append(start_time)\n",
    "                action_pack[it].append(end_time)\n",
    "    return action_pack\n",
    "                \n",
    "#action_pack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:25.133880\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "action_pack=find_action_packs_with_periods(\"all\") # любая строка, кроме fb, vk, mm, ok будет искать все паки\n",
    "now1 = datetime.now()\n",
    "print (now1-now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ищем промежутки (почти (!) без пересечений). НЕ РАЗЛИЧАЕМ ПРОМЕЖУТКИ ВНУТРИ ДРУГОГО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import fabs\n",
    "\n",
    "one_day=86400 \n",
    "\n",
    "times_s=[]\n",
    "times_e=[]\n",
    "\n",
    "for it,time_st_end in action_pack.items():\n",
    "    start_t=time_st_end[0]\n",
    "    end_t=time_st_end[1]\n",
    "    for i in range(0,len(time_st_end[0])):\n",
    "        ind_to_delete=[] #индексы будут в  порядке возр\n",
    "        acs=True\n",
    "        \n",
    "        for j in range(0,len(times_s)): #Убираем промежуток, если он входит в какой-либо другой или покрывает какой-либо другой\n",
    "            if start_t[i]>=times_s[j] and end_t[i]<=times_e[j]:\n",
    "                acs=False\n",
    "            elif start_t[i]<=times_s[j] and end_t[i]>=times_e[j]:\n",
    "                ind_to_delete.append(j)\n",
    "                \n",
    "        count=0      \n",
    "        for ind in ind_to_delete:\n",
    "                times_s.pop(ind-count)\n",
    "                times_e.pop(ind-count)\n",
    "                count+=1\n",
    "        ind_to_delete=[]\n",
    "                \n",
    "        if acs==True:\n",
    "            acs1=False\n",
    "            while acs1==False: # цикл потому что когда объеденили промежуток еще один промежуток мог стать близким |([ | ) ]. Когдаобъединили (] нам стал доступен |])\n",
    "                acs1=True\n",
    "                tmp1=None\n",
    "                tmp2=None\n",
    "                for j in range(0,len(times_s)): #Теперь у нас пересечения. Если где-нибудь начало или конец совпадают,\n",
    "                                                #то промежутки сливаются (он может совпадать с несколкими, сливаются первые попавшиеся)\n",
    "                                                #Если не совпадают, то оставляем промежуток.\n",
    "                    #print start_t[i],times_s[j],len(times_s),j\n",
    "                    if (fabs(start_t[i]-times_s[j]) <= one_day):\n",
    "                        if tmp1==None:\n",
    "                            ind_to_delete.append(j)\n",
    "                            if start_t[i]-times_s[j]>=0:\n",
    "\n",
    "                                tmp1=times_s[j]\n",
    "                                tmp2=end_t[i]\n",
    "                            else:\n",
    "                                tmp2=times_e[j]\n",
    "                                tmp1=start_t[i]\n",
    "                    elif (fabs(end_t[i]-times_e[j]) <= one_day):\n",
    "                        if tmp2==None:\n",
    "                            ind_to_delete.append(j)\n",
    "                            if end_t[i]-times_e[j]>=0:\n",
    "                                tmp1=times_s[j]\n",
    "                                tmp2=end_t[i]\n",
    "                            else:\n",
    "                                tmp2=times_e[j]\n",
    "                                tmp1=start_t[i]\n",
    "\n",
    "                count=0      \n",
    "                for ind in ind_to_delete:\n",
    "                    times_s.pop(ind-count)\n",
    "                    times_e.pop(ind-count)\n",
    "                    count+=1\n",
    "                ind_to_delete=[]\n",
    "                if tmp1!=None:\n",
    "                    acs1=False\n",
    "                    start_t[i]=tmp1\n",
    "                    end_t[i]=tmp2\n",
    "            \n",
    "            times_s.append(start_t[i])\n",
    "            times_e.append(end_t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем есть ли рядомстоящие промежутки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sc=0\n",
    "#for i in range(0,len(times_s)):\n",
    "#    for j in range(0,len(times_s)):\n",
    "#        if j!=i and times_e[i]-times_e[j]<=one_day and times_e[i]-times_e[j]>=one_day*(-1):  \n",
    "#            sc+=1\n",
    "#            print date.fromtimestamp(times_s[i]),\"---\",date.fromtimestamp(times_e[i]),\"  \",i\n",
    "#            print date.fromtimestamp(times_s[j]),\"---\",date.fromtimestamp(times_e[j]),\"  \",j\n",
    "#            print times_s[i]-times_e[j],\"\\n\\n\"\n",
    "#print sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-08 --- 2016-05-19    0\n",
      "2016-01-23 --- 2016-01-25    1\n",
      "2016-04-15 --- 2016-04-24    2\n",
      "2016-02-18 --- 2016-02-28    3\n",
      "2016-05-12 --- 2016-05-24    4\n",
      "2016-03-14 --- 2016-04-02    5\n",
      "2016-03-03 --- 2016-03-13    6\n",
      "2016-04-21 --- 2016-05-05    7\n",
      "2016-04-29 --- 2016-05-16    8\n",
      "2016-05-31 --- 2016-06-15    9\n",
      "2016-01-01 --- 2016-01-14    10\n",
      "2016-06-13 --- 2016-06-29    11\n",
      "2016-06-09 --- 2016-06-26    12\n",
      "2016-01-12 --- 2016-01-22    13\n",
      "2016-01-14 --- 2016-01-24    14\n",
      "2016-01-24 --- 2016-01-30    15\n",
      "2016-04-12 --- 2016-04-22    16\n",
      "2016-04-17 --- 2016-04-30    17\n",
      "2016-06-15 --- 2016-07-05    18\n",
      "2016-03-28 --- 2016-04-16    19\n",
      "2016-02-25 --- 2016-03-12    20\n",
      "2016-01-30 --- 2016-02-13    21\n",
      "2016-02-14 --- 2016-02-22    22\n",
      "2016-03-09 --- 2016-03-29    23\n",
      "2016-02-09 --- 2016-02-17    24\n",
      "2016-04-10 --- 2016-04-18    25\n",
      "2016-05-18 --- 2016-06-05    26\n",
      "2016-06-05 --- 2016-06-19    27\n"
     ]
    }
   ],
   "source": [
    "#for i in range(0,len(times_s)):\n",
    "#    print date.fromtimestamp(times_s[i]),\"---\",date.fromtimestamp(times_e[i]),\"  \",i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь: айдишник : паки + времена, в который данный пользователь их приобретал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_pack_period={}\n",
    "with open('trans.csv', 'rb') as csvfile:\n",
    "    spam = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "    spam.next()\n",
    "    for row in spam:\n",
    "        if id_pack_period.has_key(int(row[0]))==True:\n",
    "            val=id_pack_period.get(int(row[0]))\n",
    "            acs=False\n",
    "            for it in val:\n",
    "                if it[0]==row[5]:\n",
    "                    acs=True\n",
    "                    it.append(int(row[2]))\n",
    "            if acs==False:\n",
    "                temp=[]\n",
    "                temp.append(row[5])#название соц. сети\n",
    "                temp.append(int(row[2]))#время\n",
    "                id_pack_period[int(row[0])].append(temp)\n",
    "        else:\n",
    "            id_pack_period[int(row[0])]=[]# каждый id принимает в значение свои транзакции\n",
    "            temp=[]\n",
    "            temp.append(row[5])#название соц. сети\n",
    "            temp.append(int(row[2]))#время\n",
    "            id_pack_period[int(row[0])].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "        from datetime import datetime\n",
    "        from datetime import date\n",
    "        def write_res_to_file_name(file_name, mnsp, mncf, t_d, r_f_a, r_d):\n",
    "            id_count=0\n",
    "            now = datetime.now()\n",
    "            minSupport=mnsp\n",
    "            minConfidence=mncf\n",
    "\n",
    "            count=0\n",
    "            with open(file_name, 'w') as rs:\n",
    "                start_time=times_s\n",
    "                end_time=times_e\n",
    "                for bound in range(0,len(start_time)):\n",
    "                    ids={}\n",
    "                    # 3) если пак акционный, то забиваем данные для составления ассоциативных правил\n",
    "                    \n",
    "                    for id_id in id_pack_period:\n",
    "                        temp=[]\n",
    "                        for packs in id_pack_period[id_id]:\n",
    "                            acs=False\n",
    "                            for iterator in range(0,len(packs)-1): # проверяем покупался ли пак данным пользователем в данный промежуток времени\n",
    "                                if (packs[iterator+1]>=start_time[bound] and packs[iterator+1]<=end_time[bound]):\n",
    "                                    acs=True\n",
    "                            if acs==True:\n",
    "                                temp.append(packs[0])\n",
    "                        if len(temp)!=0:\n",
    "                            ids[id_id]=[]\n",
    "                            for item in  temp:\n",
    "                                ids[id_id].append(item)\n",
    "                    \n",
    "                    with open('file_for_transactions.csv', 'w') as csf:\n",
    "                        for key, value in ids.items():\n",
    "                            st=\"\"\n",
    "                            for i in range(0,len(value)):\n",
    "                                st=st+value[i]+','\n",
    "                            csf.write(st+'\\n')\n",
    "                    #now1 = datetime.now()\n",
    "                    #print \"файлы: \",\"  \",(now1-now)\n",
    "\n",
    "                    inFile = dataFromFile(\"file_for_transactions.csv\")\n",
    "                    \n",
    "                    items, rules, r_f_a, r_d = runApriori(inFile, minSupport, minConfidence, start_time[bound], end_time[bound], r_f_a, r_d)  \n",
    "                    \n",
    "                    id_count, t_d=printResults(items, rules, rs, id_count, t_d, start_time[bound],end_time[bound],len(ids))\n",
    "                    #print len(ids),\"-\",\n",
    "                    \n",
    "\n",
    "\n",
    "            # 4) время работы алгоритма\n",
    "            now1 = datetime.now()\n",
    "            print (now1-now)\n",
    "            return t_d, r_f_a, r_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЗАМЕЧАНИЕ:\n",
    "\n",
    "С учетом объединения промежутков, во-1, уменьшилось количество правил, а, во-2, увеличился порог. В связи с этим, необходимо было изменить **minsupport**, т.к. на 0.5 правил, с учетом порядка, не нашлось!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:41.033851\n"
     ]
    }
   ],
   "source": [
    "tabl_dict={}\n",
    "rules_for_apriori={} #ТРАНЗАКЦИИ правил\n",
    "rules_definition={} # ПОНИМЕМ КАКОЕ ПРАВИЛО, ЧТО ОБЗНАЧАЕТ (т.к. была переинициализация)\n",
    "tabl_dict, rules_for_apriori, rules_definition=write_res_to_file_name(\"res_l1_check_seq_1.txt\", 0.02, 0.5,tabl_dict, rules_for_apriori, rules_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее на полученных транзакциях правил нам нужно провести простой алгоритм АПРИОРИ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runApriori_1(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet,\n",
    "                                        transactionList,\n",
    "                                        minSupport,\n",
    "                                        freqSet)\n",
    "\n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while(currentLSet != set([])):\n",
    "        largeSet[k-1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(currentLSet,\n",
    "                                                transactionList,\n",
    "                                                minSupport,\n",
    "                                                freqSet)\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "            \"\"\"local function which Returns the support of an item\"\"\"\n",
    "            return float(freqSet[item])/len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in largeSet.items():\n",
    "        toRetItems.extend([(tuple(item), getSupport(item))\n",
    "                           for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in largeSet.items()[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence_lift = []\n",
    "                    item_A=getSupport(element)\n",
    "                    item_B=getSupport(remain)\n",
    "                    confidence_lift.append(getSupport(item)/item_A)#conf - 0\n",
    "                    if confidence_lift[0] >= minConfidence:\n",
    "                        confidence_lift.append(getSupport(item)/(item_A*item_B))#lift - 1\n",
    "                        if  item_A>item_B:\n",
    "                            confidence_lift.append(item_B)#min(minsup) - 2\n",
    "                        else:\n",
    "                            confidence_lift.append(item_A)\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)),\n",
    "                                           confidence_lift))\n",
    "    return toRetItems, toRetRules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем наш словарь с данными по работе алгоритма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_d_1={}\n",
    "with open('file_for_transactions.csv', 'w') as csf:\n",
    "    for key, value in rules_for_apriori.items():\n",
    "        st=\"\"\n",
    "        for i in range(0,len(value)):\n",
    "            st=st+value[i]+','\n",
    "        csf.write(st+'\\n')\n",
    "\n",
    "\n",
    "inFile = dataFromFile(\"file_for_transactions.csv\")\n",
    "                    \n",
    "items, rules = runApriori_1(inFile, 0.02, 0.5)  \n",
    "\n",
    "with open('fo_test_rs.csv', 'w') as rs:\n",
    "    id_count=0\n",
    "    id_count, t_d_1=printResults(items, rules, rs, id_count, t_d_1, 0,1,2)\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем ексель файл с результатами алгоритма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('g_t_strategy.csv', 'w') as csvfile_1:\n",
    "    fieldnames=[\"ID\",\"Rule\",\"Confidence\",\"Lift\",\"Support\"]\n",
    "    writer = csv.DictWriter(csvfile_1, fieldnames=fieldnames,delimiter='|')\n",
    "    writer.writeheader()\n",
    "    for key,value in t_d_1.items():\n",
    "        #print value[4],\n",
    "        writer.writerow({fieldnames[0]: key, fieldnames[1]: value[0], fieldnames[2]: value[1], fieldnames[3]: value[2],fieldnames[4]: value[3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ТАКЖЕ\n",
    "\n",
    "создаем файл для определения переинициализации правил (что за правило и когда действовало)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('definition.csv', 'w') as csvfile_1:\n",
    "    fieldnames=[\"Rule\", \"Rule's definition\",\"Date\"]\n",
    "    writer = csv.DictWriter(csvfile_1, fieldnames=fieldnames,delimiter='|')\n",
    "    writer.writeheader()\n",
    "    for key,value in rules_definition.items():\n",
    "        writer.writerow({fieldnames[0]: value[0], fieldnames[1]: key,fieldnames[2]: value[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [РЕЗУЛЬТАТ](https://public.tableau.com/profile/publish/Strat-Def/Dashboard1#!/publish-confirm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЧТО ХОРОШО БЫ ДОДЕЛАТЬ:\n",
    "\n",
    "Правила идут не по порядку. Надо отсортировать промежутки, иначе неудобно совмещать правила и дату. Также, порядок в стратегиях не учитывается, но учитывая то, что все даты даны, определить из 1=>2 или из 2=>1 не представляет труда!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
